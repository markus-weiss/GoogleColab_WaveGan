{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled1.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python2",
      "display_name": "Python 2"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/markus-weiss/GoogleColab_WaveGan/blob/master/train_wavegan.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "xonr3tGK_0QF",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 367
        },
        "outputId": "ebcf2abf-f8d7-432b-8558-459a0fbe1d3d"
      },
      "cell_type": "code",
      "source": [
        "from __future__ import print_function\n",
        "# import simple_pickle as pickle\n",
        "import os\n",
        "import time\n",
        "\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from six.moves import xrange\n",
        "\n",
        "import loader\n",
        "from wavegan import WaveGANGenerator, WaveGANDiscriminator\n",
        "from functools import reduce\n",
        "\n",
        "\n",
        "\"\"\"\n",
        "  Constants\n",
        "\"\"\"\n",
        "_FS = 16000\n",
        "_WINDOW_LEN = 16384\n",
        "_D_Z = 100\n",
        "\n",
        "\n",
        "\"\"\"\n",
        "  Trains a WaveGAN\n",
        "\"\"\"\n",
        "def train(fps, args):\n",
        "  with tf.name_scope('loader'):\n",
        "    x = loader.get_batch(fps, args.train_batch_size, _WINDOW_LEN, args.data_first_window)\n",
        "\n",
        "  # Make z vector\n",
        "  z = tf.random_uniform([args.train_batch_size, _D_Z], -1., 1., dtype=tf.float32)\n",
        "\n",
        "  # Make generator\n",
        "  with tf.variable_scope('G'):\n",
        "    G_z = WaveGANGenerator(z, train=True, **args.wavegan_g_kwargs)\n",
        "    if args.wavegan_genr_pp:\n",
        "      with tf.variable_scope('pp_filt'):\n",
        "        G_z = tf.layers.conv1d(G_z, 1, args.wavegan_genr_pp_len, use_bias=False, padding='same')\n",
        "  G_vars = tf.get_collection(tf.GraphKeys.TRAINABLE_VARIABLES, scope='G')\n",
        "\n",
        "  # Print G summary\n",
        "  print('-' * 80)\n",
        "  print('Generator vars')\n",
        "  nparams = 0\n",
        "  for v in G_vars:\n",
        "    v_shape = v.get_shape().as_list()\n",
        "    v_n = reduce(lambda x, y: x * y, v_shape)\n",
        "    nparams += v_n\n",
        "    print('{} ({}): {}'.format(v.get_shape().as_list(), v_n, v.name))\n",
        "  print('Total params: {} ({:.2f} MB)'.format(nparams, (float(nparams) * 4) / (1024 * 1024)))\n",
        "\n",
        "  # Summarize\n",
        "  tf.summary.audio('x', x, _FS)\n",
        "  tf.summary.audio('G_z', G_z, _FS)\n",
        "  G_z_rms = tf.sqrt(tf.reduce_mean(tf.square(G_z[:, :, 0]), axis=1))\n",
        "  x_rms = tf.sqrt(tf.reduce_mean(tf.square(x[:, :, 0]), axis=1))\n",
        "  tf.summary.histogram('x_rms_batch', x_rms)\n",
        "  tf.summary.histogram('G_z_rms_batch', G_z_rms)\n",
        "  tf.summary.scalar('x_rms', tf.reduce_mean(x_rms))\n",
        "  tf.summary.scalar('G_z_rms', tf.reduce_mean(G_z_rms))\n",
        "\n",
        "  # Make real discriminator\n",
        "  with tf.name_scope('D_x'), tf.variable_scope('D'):\n",
        "    D_x = WaveGANDiscriminator(x, **args.wavegan_d_kwargs)\n",
        "  D_vars = tf.get_collection(tf.GraphKeys.TRAINABLE_VARIABLES, scope='D')\n",
        "\n",
        "  # Print D summary\n",
        "  print('-' * 80)\n",
        "  print('Discriminator vars')\n",
        "  nparams = 0\n",
        "  for v in D_vars:\n",
        "    v_shape = v.get_shape().as_list()\n",
        "    v_n = reduce(lambda x, y: x * y, v_shape)\n",
        "    nparams += v_n\n",
        "    print('{} ({}): {}'.format(v.get_shape().as_list(), v_n, v.name))\n",
        "  print('Total params: {} ({:.2f} MB)'.format(nparams, (float(nparams) * 4) / (1024 * 1024)))\n",
        "  print('-' * 80)\n",
        "\n",
        "  # Make fake discriminator\n",
        "  with tf.name_scope('D_G_z'), tf.variable_scope('D', reuse=True):\n",
        "    D_G_z = WaveGANDiscriminator(G_z, **args.wavegan_d_kwargs)\n",
        "\n",
        "  # Create loss\n",
        "  D_clip_weights = None\n",
        "  if args.wavegan_loss == 'dcgan':\n",
        "    fake = tf.zeros([args.train_batch_size], dtype=tf.float32)\n",
        "    real = tf.ones([args.train_batch_size], dtype=tf.float32)\n",
        "\n",
        "    G_loss = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(\n",
        "      logits=D_G_z,\n",
        "      labels=real\n",
        "    ))\n",
        "\n",
        "    D_loss = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(\n",
        "      logits=D_G_z,\n",
        "      labels=fake\n",
        "    ))\n",
        "    D_loss += tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(\n",
        "      logits=D_x,\n",
        "      labels=real\n",
        "    ))\n",
        "\n",
        "    D_loss /= 2.\n",
        "  elif args.wavegan_loss == 'lsgan':\n",
        "    G_loss = tf.reduce_mean((D_G_z - 1.) ** 2)\n",
        "    D_loss = tf.reduce_mean((D_x - 1.) ** 2)\n",
        "    D_loss += tf.reduce_mean(D_G_z ** 2)\n",
        "    D_loss /= 2.\n",
        "  elif args.wavegan_loss == 'wgan':\n",
        "    G_loss = -tf.reduce_mean(D_G_z)\n",
        "    D_loss = tf.reduce_mean(D_G_z) - tf.reduce_mean(D_x)\n",
        "\n",
        "    with tf.name_scope('D_clip_weights'):\n",
        "      clip_ops = []\n",
        "      for var in D_vars:\n",
        "        clip_bounds = [-.01, .01]\n",
        "        clip_ops.append(\n",
        "          tf.assign(\n",
        "            var,\n",
        "            tf.clip_by_value(var, clip_bounds[0], clip_bounds[1])\n",
        "          )\n",
        "        )\n",
        "      D_clip_weights = tf.group(*clip_ops)\n",
        "  elif args.wavegan_loss == 'wgan-gp':\n",
        "    G_loss = -tf.reduce_mean(D_G_z)\n",
        "    D_loss = tf.reduce_mean(D_G_z) - tf.reduce_mean(D_x)\n",
        "\n",
        "    alpha = tf.random_uniform(shape=[args.train_batch_size, 1, 1], minval=0., maxval=1.)\n",
        "    differences = G_z - x\n",
        "    interpolates = x + (alpha * differences)\n",
        "    with tf.name_scope('D_interp'), tf.variable_scope('D', reuse=True):\n",
        "      D_interp = WaveGANDiscriminator(interpolates, **args.wavegan_d_kwargs)\n",
        "\n",
        "    LAMBDA = 10\n",
        "    gradients = tf.gradients(D_interp, [interpolates])[0]\n",
        "    slopes = tf.sqrt(tf.reduce_sum(tf.square(gradients), reduction_indices=[1, 2]))\n",
        "    gradient_penalty = tf.reduce_mean((slopes - 1.) ** 2.)\n",
        "    D_loss += LAMBDA * gradient_penalty\n",
        "  else:\n",
        "    raise NotImplementedError()\n",
        "\n",
        "  tf.summary.scalar('G_loss', G_loss)\n",
        "  tf.summary.scalar('D_loss', D_loss)\n",
        "\n",
        "  # Create (recommended) optimizer\n",
        "  if args.wavegan_loss == 'dcgan':\n",
        "    G_opt = tf.train.AdamOptimizer(\n",
        "        learning_rate=2e-4,\n",
        "        beta1=0.5)\n",
        "    D_opt = tf.train.AdamOptimizer(\n",
        "        learning_rate=2e-4,\n",
        "        beta1=0.5)\n",
        "  elif args.wavegan_loss == 'lsgan':\n",
        "    G_opt = tf.train.RMSPropOptimizer(\n",
        "        learning_rate=1e-4)\n",
        "    D_opt = tf.train.RMSPropOptimizer(\n",
        "        learning_rate=1e-4)\n",
        "  elif args.wavegan_loss == 'wgan':\n",
        "    G_opt = tf.train.RMSPropOptimizer(\n",
        "        learning_rate=5e-5)\n",
        "    D_opt = tf.train.RMSPropOptimizer(\n",
        "        learning_rate=5e-5)\n",
        "  elif args.wavegan_loss == 'wgan-gp':\n",
        "    G_opt = tf.train.AdamOptimizer(\n",
        "        learning_rate=1e-4,\n",
        "        beta1=0.5,\n",
        "        beta2=0.9)\n",
        "    D_opt = tf.train.AdamOptimizer(\n",
        "        learning_rate=1e-4,\n",
        "        beta1=0.5,\n",
        "        beta2=0.9)\n",
        "  else:\n",
        "    raise NotImplementedError()\n",
        "\n",
        "  # Create training ops\n",
        "  G_train_op = G_opt.minimize(G_loss, var_list=G_vars,\n",
        "      global_step=tf.train.get_or_create_global_step())\n",
        "  D_train_op = D_opt.minimize(D_loss, var_list=D_vars)\n",
        "\n",
        "  # Run training\n",
        "  with tf.train.MonitoredTrainingSession(\n",
        "      checkpoint_dir=args.train_dir,\n",
        "      save_checkpoint_secs=args.train_save_secs,\n",
        "      save_summaries_secs=args.train_summary_secs) as sess:\n",
        "    while True:\n",
        "      # Train discriminator\n",
        "      for i in xrange(args.wavegan_disc_nupdates):\n",
        "        sess.run(D_train_op)\n",
        "\n",
        "        # Enforce Lipschitz constraint for WGAN\n",
        "        if D_clip_weights is not None:\n",
        "          sess.run(D_clip_weights)\n",
        "\n",
        "      # Train generator\n",
        "      sess.run(G_train_op)\n",
        "\n",
        "\n",
        "\"\"\"\n",
        "  Creates and saves a MetaGraphDef for simple inference\n",
        "  Tensors:\n",
        "    'samp_z_n' int32 []: Sample this many latent vectors\n",
        "    'samp_z' float32 [samp_z_n, 100]: Resultant latent vectors\n",
        "    'z:0' float32 [None, 100]: Input latent vectors\n",
        "    'flat_pad:0' int32 []: Number of padding samples to use when flattening batch to a single audio file\n",
        "    'G_z:0' float32 [None, 16384, 1]: Generated outputs\n",
        "    'G_z_int16:0' int16 [None, 16384, 1]: Same as above but quantizied to 16-bit PCM samples\n",
        "    'G_z_flat:0' float32 [None, 1]: Outputs flattened into single audio file\n",
        "    'G_z_flat_int16:0' int16 [None, 1]: Same as above but quantized to 16-bit PCM samples\n",
        "  Example usage:\n",
        "    import tensorflow as tf\n",
        "    tf.reset_default_graph()\n",
        "\n",
        "    saver = tf.train.import_meta_graph('infer.meta')\n",
        "    graph = tf.get_default_graph()\n",
        "    sess = tf.InteractiveSession()\n",
        "    saver.restore(sess, 'model.ckpt-10000')\n",
        "\n",
        "    z_n = graph.get_tensor_by_name('samp_z_n:0')\n",
        "    _z = sess.run(graph.get_tensor_by_name('samp_z:0'), {z_n: 10})\n",
        "\n",
        "    z = graph.get_tensor_by_name('G_z:0')\n",
        "    _G_z = sess.run(graph.get_tensor_by_name('G_z:0'), {z: _z})\n",
        "\"\"\"\n",
        "def infer(args):\n",
        "  infer_dir = os.path.join(args.train_dir, 'infer')\n",
        "  if not os.path.isdir(infer_dir):\n",
        "    os.makedirs(infer_dir)\n",
        "\n",
        "  # Subgraph that generates latent vectors\n",
        "  samp_z_n = tf.placeholder(tf.int32, [], name='samp_z_n')\n",
        "  samp_z = tf.random_uniform([samp_z_n, _D_Z], -1.0, 1.0, dtype=tf.float32, name='samp_z')\n",
        "\n",
        "  # Input zo\n",
        "  z = tf.placeholder(tf.float32, [None, _D_Z], name='z')\n",
        "  flat_pad = tf.placeholder(tf.int32, [], name='flat_pad')\n",
        "\n",
        "  # Execute generator\n",
        "  with tf.variable_scope('G'):\n",
        "    G_z = WaveGANGenerator(z, train=False, **args.wavegan_g_kwargs)\n",
        "    if args.wavegan_genr_pp:\n",
        "      with tf.variable_scope('pp_filt'):\n",
        "        G_z = tf.layers.conv1d(G_z, 1, args.wavegan_genr_pp_len, use_bias=False, padding='same')\n",
        "  G_z = tf.identity(G_z, name='G_z')\n",
        "\n",
        "  # Flatten batch\n",
        "  nch = int(G_z.get_shape()[-1])\n",
        "  G_z_padded = tf.pad(G_z, [[0, 0], [0, flat_pad], [0, 0]])\n",
        "  G_z_flat = tf.reshape(G_z_padded, [-1, nch], name='G_z_flat')\n",
        "\n",
        "  # Encode to int16\n",
        "  def float_to_int16(x, name=None):\n",
        "    x_int16 = x * 32767.\n",
        "    x_int16 = tf.clip_by_value(x_int16, -32767., 32767.)\n",
        "    x_int16 = tf.cast(x_int16, tf.int16, name=name)\n",
        "    return x_int16\n",
        "  G_z_int16 = float_to_int16(G_z, name='G_z_int16')\n",
        "  G_z_flat_int16 = float_to_int16(G_z_flat, name='G_z_flat_int16')\n",
        "\n",
        "  # Create saver\n",
        "  G_vars = tf.get_collection(tf.GraphKeys.GLOBAL_VARIABLES, scope='G')\n",
        "  global_step = tf.train.get_or_create_global_step()\n",
        "  saver = tf.train.Saver(G_vars + [global_step])\n",
        "\n",
        "  # Export graph\n",
        "  tf.train.write_graph(tf.get_default_graph(), infer_dir, 'infer.pbtxt')\n",
        "\n",
        "  # Export MetaGraph\n",
        "  infer_metagraph_fp = os.path.join(infer_dir, 'infer.meta')\n",
        "  tf.train.export_meta_graph(\n",
        "      filename=infer_metagraph_fp,\n",
        "      clear_devices=True,\n",
        "      saver_def=saver.as_saver_def())\n",
        "\n",
        "  # Reset graph (in case training afterwards)\n",
        "  tf.reset_default_graph()\n",
        "\n",
        "\n",
        "\"\"\"\n",
        "  Generates a preview audio file every time a checkpoint is saved\n",
        "\"\"\"\n",
        "def preview(args):\n",
        "  import matplotlib\n",
        "  matplotlib.use('Agg')\n",
        "  import matplotlib.pyplot as plt\n",
        "  from scipy.io.wavfile import write as wavwrite\n",
        "  from scipy.signal import freqz\n",
        "\n",
        "  preview_dir = os.path.join(args.train_dir, 'preview')\n",
        "  if not os.path.isdir(preview_dir):\n",
        "    os.makedirs(preview_dir)\n",
        "\n",
        "  # Load graph\n",
        "  infer_metagraph_fp = os.path.join(args.train_dir, 'infer', 'infer.meta')\n",
        "  graph = tf.get_default_graph()\n",
        "  saver = tf.train.import_meta_graph(infer_metagraph_fp)\n",
        "\n",
        "  # Generate or restore z_i and z_o\n",
        "  z_fp = os.path.join(preview_dir, 'z.pkl')\n",
        "  if os.path.exists(z_fp):\n",
        "    with open(z_fp, 'rb') as f:\n",
        "      _zs = pickle.load(f)\n",
        "  else:\n",
        "    # Sample z\n",
        "    samp_feeds = {}\n",
        "    samp_feeds[graph.get_tensor_by_name('samp_z_n:0')] = args.preview_n\n",
        "    samp_fetches = {}\n",
        "    samp_fetches['zs'] = graph.get_tensor_by_name('samp_z:0')\n",
        "    with tf.Session() as sess:\n",
        "      _samp_fetches = sess.run(samp_fetches, samp_feeds)\n",
        "    _zs = _samp_fetches['zs']\n",
        "\n",
        "    # Save z\n",
        "    with open(z_fp, 'wb') as f:\n",
        "      pickle.dump(_zs, f)\n",
        "\n",
        "  # Set up graph for generating preview images\n",
        "  feeds = {}\n",
        "  feeds[graph.get_tensor_by_name('z:0')] = _zs\n",
        "  feeds[graph.get_tensor_by_name('flat_pad:0')] = _WINDOW_LEN // 2\n",
        "  fetches = {}\n",
        "  fetches['step'] = tf.train.get_or_create_global_step()\n",
        "  fetches['G_z'] = graph.get_tensor_by_name('G_z:0')\n",
        "  fetches['G_z_flat_int16'] = graph.get_tensor_by_name('G_z_flat_int16:0')\n",
        "  if args.wavegan_genr_pp:\n",
        "    fetches['pp_filter'] = graph.get_tensor_by_name('G/pp_filt/conv1d/kernel:0')[:, 0, 0]\n",
        "\n",
        "  # Summarize\n",
        "  G_z = graph.get_tensor_by_name('G_z_flat:0')\n",
        "  summaries = [\n",
        "      tf.summary.audio('preview', tf.expand_dims(G_z, axis=0), _FS, max_outputs=1)\n",
        "  ]\n",
        "  fetches['summaries'] = tf.summary.merge(summaries)\n",
        "  summary_writer = tf.summary.FileWriter(preview_dir)\n",
        "\n",
        "  # PP Summarize\n",
        "  if args.wavegan_genr_pp:\n",
        "    pp_fp = tf.placeholder(tf.string, [])\n",
        "    pp_bin = tf.read_file(pp_fp)\n",
        "    pp_png = tf.image.decode_png(pp_bin)\n",
        "    pp_summary = tf.summary.image('pp_filt', tf.expand_dims(pp_png, axis=0))\n",
        "\n",
        "  # Loop, waiting for checkpoints\n",
        "  ckpt_fp = None\n",
        "  while True:\n",
        "    latest_ckpt_fp = tf.train.latest_checkpoint(args.train_dir)\n",
        "    if latest_ckpt_fp != ckpt_fp:\n",
        "      print('Preview: {}'.format(latest_ckpt_fp))\n",
        "\n",
        "      with tf.Session() as sess:\n",
        "        saver.restore(sess, latest_ckpt_fp)\n",
        "\n",
        "        _fetches = sess.run(fetches, feeds)\n",
        "\n",
        "        _step = _fetches['step']\n",
        "\n",
        "      preview_fp = os.path.join(preview_dir, '{}.wav'.format(str(_step).zfill(8)))\n",
        "      wavwrite(preview_fp, _FS, _fetches['G_z_flat_int16'])\n",
        "\n",
        "      summary_writer.add_summary(_fetches['summaries'], _step)\n",
        "\n",
        "      if args.wavegan_genr_pp:\n",
        "        w, h = freqz(_fetches['pp_filter'])\n",
        "\n",
        "        fig = plt.figure()\n",
        "        plt.title('Digital filter frequncy response')\n",
        "        ax1 = fig.add_subplot(111)\n",
        "\n",
        "        plt.plot(w, 20 * np.log10(abs(h)), 'b')\n",
        "        plt.ylabel('Amplitude [dB]', color='b')\n",
        "        plt.xlabel('Frequency [rad/sample]')\n",
        "\n",
        "        ax2 = ax1.twinx()\n",
        "        angles = np.unwrap(np.angle(h))\n",
        "        plt.plot(w, angles, 'g')\n",
        "        plt.ylabel('Angle (radians)', color='g')\n",
        "        plt.grid()\n",
        "        plt.axis('tight')\n",
        "\n",
        "        _pp_fp = os.path.join(preview_dir, '{}_ppfilt.png'.format(str(_step).zfill(8)))\n",
        "        plt.savefig(_pp_fp)\n",
        "\n",
        "        with tf.Session() as sess:\n",
        "          _summary = sess.run(pp_summary, {pp_fp: _pp_fp})\n",
        "          summary_writer.add_summary(_summary, _step)\n",
        "\n",
        "      print('Done')\n",
        "\n",
        "      ckpt_fp = latest_ckpt_fp\n",
        "\n",
        "    time.sleep(1)\n",
        "\n",
        "\n",
        "\"\"\"\n",
        "  Computes inception score every time a checkpoint is saved\n",
        "\"\"\"\n",
        "def incept(args):\n",
        "  incept_dir = os.path.join(args.train_dir, 'incept')\n",
        "  if not os.path.isdir(incept_dir):\n",
        "    os.makedirs(incept_dir)\n",
        "\n",
        "  # Load GAN graph\n",
        "  gan_graph = tf.Graph()\n",
        "  with gan_graph.as_default():\n",
        "    infer_metagraph_fp = os.path.join(args.train_dir, 'infer', 'infer.meta')\n",
        "    gan_saver = tf.train.import_meta_graph(infer_metagraph_fp)\n",
        "    score_saver = tf.train.Saver(max_to_keep=1)\n",
        "  gan_z = gan_graph.get_tensor_by_name('z:0')\n",
        "  gan_G_z = gan_graph.get_tensor_by_name('G_z:0')[:, :, 0]\n",
        "  gan_step = gan_graph.get_tensor_by_name('global_step:0')\n",
        "\n",
        "  # Load or generate latents\n",
        "  z_fp = os.path.join(incept_dir, 'z.pkl')\n",
        "  if os.path.exists(z_fp):\n",
        "    with open(z_fp, 'rb') as f:\n",
        "      _zs = pickle.load(f)\n",
        "  else:\n",
        "    gan_samp_z_n = gan_graph.get_tensor_by_name('samp_z_n:0')\n",
        "    gan_samp_z = gan_graph.get_tensor_by_name('samp_z:0')\n",
        "    with tf.Session(graph=gan_graph) as sess:\n",
        "      _zs = sess.run(gan_samp_z, {gan_samp_z_n: args.incept_n})\n",
        "    with open(z_fp, 'wb') as f:\n",
        "      pickle.dump(_zs, f)\n",
        "\n",
        "  # Load classifier graph\n",
        "  incept_graph = tf.Graph()\n",
        "  with incept_graph.as_default():\n",
        "    incept_saver = tf.train.import_meta_graph(args.incept_metagraph_fp)\n",
        "  incept_x = incept_graph.get_tensor_by_name('x:0')\n",
        "  incept_preds = incept_graph.get_tensor_by_name('scores:0')\n",
        "  incept_sess = tf.Session(graph=incept_graph)\n",
        "  incept_saver.restore(incept_sess, args.incept_ckpt_fp)\n",
        "\n",
        "  # Create summaries\n",
        "  summary_graph = tf.Graph()\n",
        "  with summary_graph.as_default():\n",
        "    incept_mean = tf.placeholder(tf.float32, [])\n",
        "    incept_std = tf.placeholder(tf.float32, [])\n",
        "    summaries = [\n",
        "        tf.summary.scalar('incept_mean', incept_mean),\n",
        "        tf.summary.scalar('incept_std', incept_std)\n",
        "    ]\n",
        "    summaries = tf.summary.merge(summaries)\n",
        "  summary_writer = tf.summary.FileWriter(incept_dir)\n",
        "\n",
        "  # Loop, waiting for checkpoints\n",
        "  ckpt_fp = None\n",
        "  _best_score = 0.\n",
        "  while True:\n",
        "    latest_ckpt_fp = tf.train.latest_checkpoint(args.train_dir)\n",
        "    if latest_ckpt_fp != ckpt_fp:\n",
        "      print('Incept: {}'.format(latest_ckpt_fp))\n",
        "\n",
        "      sess = tf.Session(graph=gan_graph)\n",
        "\n",
        "      gan_saver.restore(sess, latest_ckpt_fp)\n",
        "\n",
        "      _step = sess.run(gan_step)\n",
        "\n",
        "      _G_zs = []\n",
        "      for i in xrange(0, args.incept_n, 100):\n",
        "        _G_zs.append(sess.run(gan_G_z, {gan_z: _zs[i:i+100]}))\n",
        "      _G_zs = np.concatenate(_G_zs, axis=0)\n",
        "\n",
        "      _preds = []\n",
        "      for i in xrange(0, args.incept_n, 100):\n",
        "        _preds.append(incept_sess.run(incept_preds, {incept_x: _G_zs[i:i+100]}))\n",
        "      _preds = np.concatenate(_preds, axis=0)\n",
        "\n",
        "      # Split into k groups\n",
        "      _incept_scores = []\n",
        "      split_size = args.incept_n // args.incept_k\n",
        "      for i in xrange(args.incept_k):\n",
        "        _split = _preds[i * split_size:(i + 1) * split_size]\n",
        "        _kl = _split * (np.log(_split) - np.log(np.expand_dims(np.mean(_split, 0), 0)))\n",
        "        _kl = np.mean(np.sum(_kl, 1))\n",
        "        _incept_scores.append(np.exp(_kl))\n",
        "\n",
        "      _incept_mean, _incept_std = np.mean(_incept_scores), np.std(_incept_scores)\n",
        "\n",
        "      # Summarize\n",
        "      with tf.Session(graph=summary_graph) as summary_sess:\n",
        "        _summaries = summary_sess.run(summaries, {incept_mean: _incept_mean, incept_std: _incept_std})\n",
        "      summary_writer.add_summary(_summaries, _step)\n",
        "\n",
        "      # Save\n",
        "      if _incept_mean > _best_score:\n",
        "        score_saver.save(sess, os.path.join(incept_dir, 'best_score'), _step)\n",
        "        _best_score = _incept_mean\n",
        "\n",
        "      sess.close()\n",
        "\n",
        "      print('Done')\n",
        "\n",
        "      ckpt_fp = latest_ckpt_fp\n",
        "\n",
        "    time.sleep(1)\n",
        "\n",
        "  incept_sess.close()\n",
        "\n",
        "\n",
        "if __name__ == '__main__':\n",
        "  import argparse\n",
        "  import glob\n",
        "  import sys\n",
        "\n",
        "  parser = argparse.ArgumentParser()\n",
        "\n",
        "  parser.add_argument('mode', type=str, choices=['train', 'preview', 'incept', 'infer'])\n",
        "  parser.add_argument('train_dir', type=str,\n",
        "      help='Training directory')\n",
        "\n",
        "  data_args = parser.add_argument_group('Data')\n",
        "  data_args.add_argument('--data_dir', type=str,\n",
        "      help='Data directory')\n",
        "  data_args.add_argument('--data_first_window', action='store_true', dest='data_first_window',\n",
        "      help='If set, only use the first window from each audio example')\n",
        "\n",
        "  wavegan_args = parser.add_argument_group('WaveGAN')\n",
        "  wavegan_args.add_argument('--wavegan_kernel_len', type=int,\n",
        "      help='Length of 1D filter kernels')\n",
        "  wavegan_args.add_argument('--wavegan_dim', type=int,\n",
        "      help='Dimensionality multiplier for model of G and D')\n",
        "  wavegan_args.add_argument('--wavegan_batchnorm', action='store_true', dest='wavegan_batchnorm',\n",
        "      help='Enable batchnorm')\n",
        "  wavegan_args.add_argument('--wavegan_disc_nupdates', type=int,\n",
        "      help='Number of discriminator updates per generator update')\n",
        "  wavegan_args.add_argument('--wavegan_loss', type=str, choices=['dcgan', 'lsgan', 'wgan', 'wgan-gp'],\n",
        "      help='Which GAN loss to use')\n",
        "  wavegan_args.add_argument('--wavegan_genr_upsample', type=str, choices=['zeros', 'nn', 'lin', 'cub'],\n",
        "      help='Generator upsample strategy')\n",
        "  wavegan_args.add_argument('--wavegan_genr_pp', action='store_true', dest='wavegan_genr_pp',\n",
        "      help='If set, use post-processing filter')\n",
        "  wavegan_args.add_argument('--wavegan_genr_pp_len', type=int,\n",
        "      help='Length of post-processing filter for DCGAN')\n",
        "  wavegan_args.add_argument('--wavegan_disc_phaseshuffle', type=int,\n",
        "      help='Radius of phase shuffle operation')\n",
        "\n",
        "  train_args = parser.add_argument_group('Train')\n",
        "  train_args.add_argument('--train_batch_size', type=int,\n",
        "      help='Batch size')\n",
        "  train_args.add_argument('--train_save_secs', type=int,\n",
        "      help='How often to save model')\n",
        "  train_args.add_argument('--train_summary_secs', type=int,\n",
        "      help='How often to report summaries')\n",
        "\n",
        "  preview_args = parser.add_argument_group('Preview')\n",
        "  preview_args.add_argument('--preview_n', type=int,\n",
        "      help='Number of samples to preview')\n",
        "\n",
        "  incept_args = parser.add_argument_group('Incept')\n",
        "  incept_args.add_argument('--incept_metagraph_fp', type=str,\n",
        "      help='Inference model for inception score')\n",
        "  incept_args.add_argument('--incept_ckpt_fp', type=str,\n",
        "      help='Checkpoint for inference model')\n",
        "  incept_args.add_argument('--incept_n', type=int,\n",
        "      help='Number of generated examples to test')\n",
        "  incept_args.add_argument('--incept_k', type=int,\n",
        "      help='Number of groups to test')\n",
        "\n",
        "  parser.set_defaults(\n",
        "    data_dir=None,\n",
        "    data_first_window=False,\n",
        "    wavegan_kernel_len=25,\n",
        "    wavegan_dim=64,\n",
        "    wavegan_batchnorm=False,\n",
        "    wavegan_disc_nupdates=5,\n",
        "    wavegan_loss='wgan-gp',\n",
        "    wavegan_genr_upsample='zeros',\n",
        "    wavegan_genr_pp=False,\n",
        "    wavegan_genr_pp_len=512,\n",
        "    wavegan_disc_phaseshuffle=2,\n",
        "    train_batch_size=64,\n",
        "    train_save_secs=300,\n",
        "    train_summary_secs=120,\n",
        "    preview_n=32,\n",
        "    incept_metagraph_fp='./eval/inception/infer.meta',\n",
        "    incept_ckpt_fp='./eval/inception/best_acc-103005',\n",
        "    incept_n=5000,\n",
        "    incept_k=10)\n",
        "\n",
        "  args = parser.parse_args()\n",
        "\n",
        "  # Make train dir\n",
        "  if not os.path.isdir(args.train_dir):\n",
        "    os.makedirs(args.train_dir)\n",
        "\n",
        "  # Save args\n",
        "  with open(os.path.join(args.train_dir, 'args.txt'), 'w') as f:\n",
        "    f.write('\\n'.join([str(k) + ',' + str(v) for k, v in sorted(vars(args).items(), key=lambda x: x[0])]))\n",
        "\n",
        "  # Make model kwarg dicts\n",
        "  setattr(args, 'wavegan_g_kwargs', {\n",
        "      'kernel_len': args.wavegan_kernel_len,\n",
        "      'dim': args.wavegan_dim,\n",
        "      'use_batchnorm': args.wavegan_batchnorm,\n",
        "      'upsample': args.wavegan_genr_upsample\n",
        "  })\n",
        "  setattr(args, 'wavegan_d_kwargs', {\n",
        "      'kernel_len': args.wavegan_kernel_len,\n",
        "      'dim': args.wavegan_dim,\n",
        "      'use_batchnorm': args.wavegan_batchnorm,\n",
        "      'phaseshuffle_rad': args.wavegan_disc_phaseshuffle\n",
        "  })\n",
        "\n",
        "  # Assign appropriate split for mode\n",
        "  if args.mode == 'train':\n",
        "    split = 'train'\n",
        "  else:\n",
        "    split = None\n",
        "\n",
        "  # Find fps for split\n",
        "  if split is not None:\n",
        "    fps = glob.glob(os.path.join(args.data_dir, split) + '*.tfrecord')\n",
        "\n",
        "  if args.mode == 'train':\n",
        "    infer(args)\n",
        "    train(fps, args)\n",
        "  elif args.mode == 'preview':\n",
        "    preview(args)\n",
        "  elif args.mode == 'incept':\n",
        "    incept(args)\n",
        "  elif args.mode == 'infer':\n",
        "    infer(args)\n",
        "  else:\n",
        "    raise NotImplementedError()\n",
        "\n"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ImportError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m\u001b[0m",
            "\u001b[0;31mImportError\u001b[0mTraceback (most recent call last)",
            "\u001b[0;32m<ipython-input-5-eb9f739fe2db>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msix\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmoves\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mxrange\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mloader\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mwavegan\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mWaveGANGenerator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mWaveGANDiscriminator\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mfunctools\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mreduce\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mImportError\u001b[0m: No module named loader",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ]
        }
      ]
    }
  ]
}